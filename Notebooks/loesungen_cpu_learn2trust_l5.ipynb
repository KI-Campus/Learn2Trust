{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af3e1212",
   "metadata": {
    "id": "NuHt3Shp3PTL"
   },
   "source": [
    "# KI-Campus: Learn2Trust\n",
    "## Lektion 5: Segmentierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9bf70f",
   "metadata": {
    "id": "woU7mUz_Vbdj"
   },
   "source": [
    "### 1. Einführung\n",
    "In dieser Lektion geht es darum, wie Künstliche Intelligenz in der medizinischen Bildanalyse dazu eingesetzt werden kann, um medizinische Bildobjekte zu segmentieren.\n",
    "\n",
    "Am Beispiel von Röntgenthoraxdaten, die zur Diagnostik von Pneumonie aquiriert wurden, wird demonstriert, wie ein einfaches Segmentierungsnetzwerk programmiert werden kann. Dieses Netzwerk soll entscheiden, wo sich die Lungenflügel, Schlüsselbeine und das Herz befinden.\n",
    "\n",
    "In den verschiedenen Unterkapiteln wird zunächst der Beispieldatensatz gezeigt und anschließend durch Netzwerkerstellung, -training und -evaluation geführt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c4550",
   "metadata": {
    "id": "oJv51vc_I069"
   },
   "source": [
    "*Importieren von benötigten Packages und weiteren Dateien:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361f002",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6ZS7etdp9bk",
    "outputId": "3a5045fd-7ba5-4012-b5e8-72c16edd19f0"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# import further python files\n",
    "import network\n",
    "import utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04217fa6",
   "metadata": {
    "id": "WorIul1_C9Pg"
   },
   "source": [
    "### 2. Datensatz\n",
    "Der Datensatz für diese Lektion ist der JSRT Datensatz [1]. Dieser enthält 247 konventionelle Röntgenaufnahmen des Thorax. Wenn der Datensatz geladen wurde, werden Beispielbilder visualisiert und optional Segmentierungen angezeigt, die von Experten erstellt wurden und als Grundwahrheit genutzt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45006303",
   "metadata": {
    "id": "N86hAAl8JFfk"
   },
   "source": [
    "*Laden des Datensatzes, der für das Pretraining verwendet wurde (Bilddaten und zugehörige Segmentierungen):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07895867",
   "metadata": {
    "id": "8djDCEKTJJEs"
   },
   "outputs": [],
   "source": [
    "# load images\n",
    "imgs_pretrain = torch.load('jsrt_img_and_seg.pth')['JSRT_img'].unsqueeze(1).float()\n",
    "imgs_pretrain = imgs_pretrain.clone()\n",
    "\n",
    "# load segmentations\n",
    "segs_pretrain = torch.load('jsrt_img_and_seg.pth')['JSRT_seg'].long()\n",
    "segs_pretrain = segs_pretrain.clone()\n",
    "\n",
    "# rescale images\n",
    "imgs_pretrain -= 1500\n",
    "imgs_pretrain /= 1000\n",
    "\n",
    "# remove two segmentation labels from the data \n",
    "# we do this as we are only interested in training the network with 3 target \n",
    "# classes (4 inlcuding the background) to later enable a fine-tuning\n",
    "segs_pretrain[segs_pretrain==2] = 0\n",
    "segs_pretrain[segs_pretrain==4] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7aa44",
   "metadata": {
    "id": "rcVxhK9kCMF4"
   },
   "source": [
    "*Darstellung einer 4-Klassen-Segmentierung zum Pretraining des Modells:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b36b6f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IeO7amp0CLeI",
    "outputId": "0f0a066b-1d2a-4918-b16c-282eda6175fd"
   },
   "outputs": [],
   "source": [
    "# visualize example segmentation\n",
    "plt.imshow(segs_pretrain[0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# print information about the dataset\n",
    "print(\"Größe des Datensatz Tensors: \", imgs_pretrain.shape)\n",
    "print(\"Größe der Bilder (pixel x pixel): \", imgs_pretrain.shape[2:])\n",
    "print(\"Anzahl der Bilder im Datensatz: \", imgs_pretrain.shape[0])\n",
    "print(\"Größe des Segmentierungs Tensors: \", segs_pretrain.shape)\n",
    "print(\"Anzahl der Label: \", len(segs_pretrain.reshape(-1).unique()))\n",
    "print(\"Verfügbare Label: \", segs_pretrain.reshape(-1).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b1618",
   "metadata": {
    "id": "EFIjtVXbyBzK"
   },
   "source": [
    "*Laden von 10 Bildern für das Finetuning sowie Laden von Testdaten zur Evaluation des Modells nach Finetuning:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa4ef8",
   "metadata": {
    "id": "IQXcOQ9EpSzJ"
   },
   "outputs": [],
   "source": [
    "# load images and segmentations for finetuning\n",
    "imgs_finetune = torch.load('jsrt_img_and_seg10.pth')['img'].unsqueeze(1).float()\n",
    "imgs_finetune = imgs_finetune.clone()\n",
    "segs_finetune = torch.load('jsrt_img_and_seg10.pth')['seg'].long()\n",
    "   \n",
    "# load test data\n",
    "imgs_testset = torch.load('jsrt_img_and_seg_test.pth')['img'].unsqueeze(1).float()\n",
    "segs_testset = torch.load('jsrt_img_and_seg_test.pth')['seg'].long()\n",
    "imgs_testset = imgs_testset.clone()\n",
    "\n",
    "# rescale image values\n",
    "imgs_testset = (imgs_testset - 1500) / 1000\n",
    "imgs_finetune = (imgs_finetune - 1500) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a61fb",
   "metadata": {
    "id": "C-L_WuQgGk_v"
   },
   "source": [
    "Diese Daten besitzen 2 zusätzlichen Labelklassen, die das Netzwerk segmentieren soll.\n",
    "\n",
    "*Darstellung einer 6-Klassen-Segmentierung:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59216d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt9cXfWkGiIt",
    "outputId": "8d49c93e-99dd-4e30-b862-c748c04c01a4"
   },
   "outputs": [],
   "source": [
    "# plot segmentation map\n",
    "plt.imshow(segs_finetune[0])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# print information about the dataset\n",
    "print(\"Größe des Datensatz Tensors: \", imgs_finetune.shape)\n",
    "print(\"Größe der Bilder (pixel x pixel): \", imgs_finetune.shape[2:])\n",
    "print(\"Anzahl der Bilder im Datensatz: \", imgs_finetune.shape[0])\n",
    "print(\"Größe des Segmentierungs Tensors: \", segs_finetune.shape)\n",
    "print(\"Anzahl der Label: \", len(segs_finetune.reshape(-1).unique()))\n",
    "print(\"Verfügbare Label: \", segs_finetune.reshape(-1).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87649860",
   "metadata": {
    "id": "H6_sEWAIFRHX"
   },
   "source": [
    "### 3. Netzwerkarchitektur\n",
    "Die Netzwerkarchitektur ist das sogenannte MobileNetV3 [2].\n",
    "\n",
    "In dieser Lektion wird eine bereits vortrainierte Version des Deep-Learning-Modell verwendet. Dieses hat bereits gelernt, den rechten Lungenflügel, das rechte Schlüsselbein und das Herz zu segmentieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acb7ab",
   "metadata": {
    "id": "O33UW-bry8k9"
   },
   "source": [
    "*Laden des vortrainierten Modells/Netzwerks:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127135f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1go2dWfpSJt",
    "outputId": "71b2bacd-3d5f-45ea-fe3b-c5f2027bc5bb"
   },
   "outputs": [],
   "source": [
    "# Initialization of the model\n",
    "model_pretrained = network.lraspp_mobilenet_v3_large()\n",
    "\n",
    "# Adaptation of the input layer for processing images with one input channel \n",
    "# (e.g grayscale images)\n",
    "model_pretrained.backbone['0'][0] = torch.nn.Conv2d(1,16,3,stride=2,padding=1)\n",
    "\n",
    "# Adaptation of the classifier for the correct number of classes\n",
    "# here: four label classes: background, right lung, right collarbone, heart\n",
    "model_pretrained.classifier.low_classifier = torch.nn.Conv2d(40,4,1)\n",
    "model_pretrained.classifier.high_classifier = torch.nn.Conv2d(128,4,1)\n",
    "\n",
    "\n",
    "# Load pretrained network\n",
    "state_dict = torch.load('Learn2Trust_JSRT_LRASPP_dict.pth')\n",
    "model_pretrained.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54171364-94d0-4557-a409-adfa8f4b0569",
   "metadata": {},
   "source": [
    "*Vorhersage mit auf vier Klassen vortrainiertem KI-Modell:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    # pass through model backbone\n",
    "    features = model_pretrained.backbone(imgs_pretrain)\n",
    "\n",
    "    # pass through classifier and argmax()\n",
    "    prediction_pretrained = F.interpolate(model_pretrained.classifier(features),scale_factor=8,mode='bilinear').argmax(1)\n",
    "    \n",
    "    \n",
    "imcat = utils.cat_images(imgs_pretrain[:8,0],clip=True)\n",
    "segcat = utils.cat_images(prediction_pretrained[:8])\n",
    "seg_rgb = utils.color_rgb(imcat,segcat)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(imcat,'gray')\n",
    "ax.imshow(seg_rgb,alpha=0.5, interpolation='None')\n",
    "ax.axis('off')\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52521a6",
   "metadata": {
    "id": "bYRTntSpW_GX"
   },
   "source": [
    "### 4. Fine-Tuning\n",
    "Das geladene Netzwerk wurde bereits vortrainiert und muss im Folgenden durch ein erneutes Training verfeinert beziehungsweise auf die Segmentierung von fünf Klassen angepasst werden. \n",
    "\n",
    "Das vortrainierte Modell zu nutzen und anzupassen, um zusätzlich auch den linken Lungenflügel und das linke Schlüsselbein zu segmentieren, führt zu einem deutlich schnelleren Lernprozess als wenn das Modell komplett neu trainiert werden müsste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7dea59",
   "metadata": {
    "id": "giKuDkT9MvNI"
   },
   "source": [
    "*Anpassungen für das Fine-Tuning:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd46734",
   "metadata": {
    "id": "ngpr88VSMnwe"
   },
   "outputs": [],
   "source": [
    "# Model for fine-tuning \n",
    "model_finetuning = network.lraspp_mobilenet_v3_large()\n",
    "\n",
    "#first: load weights of pretrained model (same code as in notebook cell #6)\n",
    "model_finetuning.backbone['0'][0] = torch.nn.Conv2d(1,16,3,stride=2,padding=1)\n",
    "model_finetuning.classifier.low_classifier = torch.nn.Conv2d(40,4,1)\n",
    "model_finetuning.classifier.high_classifier = torch.nn.Conv2d(128,4,1)\n",
    "model_finetuning.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "# second: modify architecture for additional label classes\n",
    "\n",
    "# As two further annotated structures should be learnt during the fine-tuning, \n",
    "# the network needs to be able to process there two additional classes.\n",
    "model_finetuning.classifier.low_classifier = torch.nn.Conv2d(40,6,1)\n",
    "model_finetuning.classifier.high_classifier = torch.nn.Conv2d(128,6,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a87f41",
   "metadata": {},
   "source": [
    "*Definition verschiedener Trainingsparameter für das Finetuning:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd225b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of epochs for fine-tuning\n",
    "n_epochs = 2500\n",
    "\n",
    "# initialize tensor for all loss values\n",
    "run_loss = torch.zeros(n_epochs)\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.Adam(model_finetuning.parameters(),lr=0.001)\n",
    "\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9ca1",
   "metadata": {
    "id": "ueQ_DyG-Cxbs"
   },
   "source": [
    "*Trainingsschleife für das Finetuning:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba00e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fine-tuning\n",
    "model_finetuning.train()\n",
    "\n",
    "t0 = t2 = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    idx = torch.randperm(10)[:8]\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    img = imgs_finetune[idx]\n",
    "    seg = segs_finetune[idx]\n",
    "    img_aug, seg_aug  = utils.aug_img_and_seg(img, seg)\n",
    "    predict = model_finetuning(img_aug)\n",
    "    loss = loss_function(predict['out'],seg_aug)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    run_loss[epoch] = loss.item()\n",
    "\n",
    "    if(epoch%50==49):\n",
    "        t1 = time.time()\n",
    "        print(f'iteration {epoch}/{n_epochs}; duration: {round(t1-t2, 2)}s; loss: {run_loss[epoch].item()}')\n",
    "        t2 = t1\n",
    "        \n",
    "t1 = time.time()\n",
    "print(f'Finetuning finished. Total duration: {round(t1-t0, 2)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a934421c",
   "metadata": {
    "id": "livuElhvTBrN"
   },
   "source": [
    "*Plotten der Loss-Kurve:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84312523",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "qFzYEFpt07sV",
    "outputId": "9f898135-ac9e-4da9-e3aa-0f1e65ef63a6"
   },
   "outputs": [],
   "source": [
    "# plot loss curve\n",
    "plt.semilogy(run_loss[:n_epochs])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train loss')\n",
    "plt.title('Loss Finetuning')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db78167e",
   "metadata": {
    "id": "PRmiTBqlTibr"
   },
   "source": [
    "### 5. Evaluation\n",
    "Im vorherigen Unterkapitel Training wurde das Modell einem erneuten Training unterzogen. Dieses Modell soll jetzt während der sogenannten Inferenz auf die Testdaten angewendet werden, um zu evaluieren, wie gut das Modell die Bilder segmentieren kann, die ihm während der Trainingsphase noch nicht präsentiert wurden.\n",
    "\n",
    "Während der Evaluation wird der Dice-Koeffizient bestimmt, der die Genauigkeit der Segmentierung angibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cd984",
   "metadata": {
    "id": "-frp2FbVC6mW"
   },
   "source": [
    "*Evaluation und Ausgabe der Ergebnisse:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model_finetuning.cpu()\n",
    "\n",
    "with torch.no_grad():    \n",
    "\n",
    "    # pass through model backbone\n",
    "    features = model_finetuning.backbone(imgs_testset)\n",
    "\n",
    "    # pass through classifier and argmax()\n",
    "    prediction = F.interpolate(model_finetuning.classifier(features), scale_factor=8, mode='bilinear').argmax(1)\n",
    "    \n",
    "d0 = torch.zeros(len(imgs_testset),5)\n",
    "for i in range(len(imgs_testset)):\n",
    "    d0[i] = utils.dice_coeff(segs_testset[i].contiguous(),prediction[i].contiguous(),6)\n",
    "    \n",
    "print(len(imgs_testset), ' Testbilder zur Evaluation' )\n",
    "print(f'\\nMittelwert über alle Labelklassen: {d0.mean()}\\n\\nMittelwert Dice-Koeffizient für einzelne Labelklassen:\\n  Label1: Rechter Lungenflügel: {d0[:,0].mean()}\\n  Label2: Linker Lungenflügel: {d0[:,1].mean()}\\n  Label3: Rechtes Schlüsselbein: {d0[:,2].mean()}\\n  Label4: Linkes Schlüsselbein: {d0[:,3].mean()}\\n  Label5: Herz: {d0[:,4].mean()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef50d96",
   "metadata": {
    "id": "I7P6SRG2T0tM"
   },
   "source": [
    "*Visualisierung von acht segmentierten Testdatensätzen:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0ff993",
   "metadata": {
    "id": "GJhASThT07ku"
   },
   "outputs": [],
   "source": [
    "# plotting\n",
    "imcat = utils.cat_images(imgs_testset[:8,0].cpu(),True)\n",
    "segcat = utils.cat_images(prediction[:8])\n",
    "print(imcat.shape, segcat.shape)\n",
    "imrgb = utils.color_rgb(imcat,segcat)\n",
    "f = plt.figure()\n",
    "plt.imshow(imcat,'gray')\n",
    "plt.imshow(imrgb,alpha=0.4)\n",
    "plt.axis('off')\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a197c",
   "metadata": {
    "id": "-ts8nqYSYQFl"
   },
   "source": [
    "*Visualisierung der gelernten Merkmale:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "with torch.no_grad():\n",
    "    features = model_finetuning.backbone(imgs_testset)\n",
    "    features['low'] = features['low'].cpu().float()\n",
    "    features['high'] = features['high'].cpu().float()\n",
    "    \n",
    "    print(\"Größe der 'low' Features: \", features['low'].shape)\n",
    "    print(\"Größe der 'high' Features: \", features['high'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a58e62",
   "metadata": {
    "id": "NAUJkyIGYTmC"
   },
   "outputs": [],
   "source": [
    "channel_low = torch.randint(0, features['low'].shape[1] - 1, (1,))\n",
    "print('visualisations for channel_low #', channel_low.item())\n",
    "\n",
    "imcat = utils.cat_images(features['low'][:8, channel_low], clip=False, size=32)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(imcat)\n",
    "ax.axis('off')\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329d5a",
   "metadata": {
    "id": "l5fHKY1uYZEc"
   },
   "outputs": [],
   "source": [
    "channel_high = torch.randint(0, features['high'].shape[1] - 1, (1,))\n",
    "print('visualisations for channel_high #', channel_high.item())\n",
    "\n",
    "imcat = utils.cat_images(features['high'][:8, channel_high:(channel_high + 1)].mean(1), clip=False, size=16)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(imcat)\n",
    "ax.axis('off')\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d1d0e",
   "metadata": {},
   "source": [
    "[1] *Shiraishi, Junji, et al. \"Development of a digital image database for chest radiographs with and without a lung nodule: receiver operating \n",
    "                  characteristic analysis of radiologists' detection of pulmonary nodules.\" American Journal of Roentgenology 174.1 (2000): 71-74.*\n",
    "                  \n",
    "[2]  *Howard, Andrew, et al. \"Searching for mobilenetv3.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.* (Link zu Preprint: https://arxiv.org/abs/1905.02244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc37ac2-64a1-49f9-ac61-339c8c3df0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "woU7mUz_Vbdj",
    "WorIul1_C9Pg",
    "H6_sEWAIFRHX"
   ],
   "name": "notebook_learn2trust_l5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
