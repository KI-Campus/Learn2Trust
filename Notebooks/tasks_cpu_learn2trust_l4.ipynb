{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3C11lOCCfk9"
   },
   "source": [
    "# KI-Campus: Learn2Trust\n",
    "## Lektion 4: Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woU7mUz_Vbdj"
   },
   "source": [
    "### 1. Einführung\n",
    "In dieser Lektion geht es darum, wie Künstliche Intelligenz (KI) in der medizinischen Bildanalyse dazu eingesetzt werden kann, um Klassifikationsentscheidungen zu treffen.\n",
    "\n",
    "Am Beispiel von Röntgenthoraxdaten (https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia), die zur Diagnostik von Pneumonie aquiriert wurden, wird demonstriert, wie ein einfaches Klassifikationsnetzwerk programmiert werden kann. Dieses Klassifikationsnetzwerk soll entscheiden, ob in einem präsentierten Eingabebild eine Pneumonie zu erkennen ist oder nicht.\n",
    "\n",
    "In den verschiedenen Unterkapiteln wird zunächst der Beispieldatensatz gezeigt und anschließend durch Netzwerkerstellung, -training und -evaluation geführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHrE3-NQ69XV"
   },
   "source": [
    "*Importieren von benötigten Paketen und anderen Dateien:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsY19AtPTQOS",
    "outputId": "648ddf36-2429-47d3-b7c5-e52615446f23"
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "torch.manual_seed(9999);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WorIul1_C9Pg"
   },
   "source": [
    "### 2. Datensatz\n",
    "Der Datensatz für diese Lektion besteht aus Röntgenaufnahmen des Thorax, die erstellt wurden, um Pneumonie (viral oder bakteriell) zu diagnositizieren. Wenn der Datensatz geladen wurde, werden Beispielbilder visualisiert und optional Label angezeigt, die angeben, ob Experten bei den vorliegenden Aufnahmen eine Pneumonie diagnostiziert haben oder nicht.\n",
    "\n",
    "Der Datensatz besteht aus insgesamt 5000 Bildern. Davon sind 3990 Röntgenbilder Patienten zuzuordnen, bei denen eine Pneumonie diagnostiziert wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SntlpnEQ7F5n"
   },
   "source": [
    "*Laden der Bilddaten und den zugehörigen Labeln:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tQe7IKGTQOW",
    "outputId": "5b799530-c054-419f-a275-bf12ca362915"
   },
   "outputs": [],
   "source": [
    "# load image and label datasets as tensors\n",
    "data_img = torch.from_numpy(np.load('../StreamlitApps/Lektion-4/l2t_data/pneumonia_detection_data_img.npz')['arr_0']).float()[:5000]\n",
    "data_label = torch.load('../StreamlitApps/Lektion-4/l2t_data/pneumonia_detection_data_label.pth')[:5000]\n",
    "print(f'shape of data_img: {data_img.shape}')  # shape = (N: number of data, C: channel, H: height, W: width)\n",
    "print(f'shape of data_label: {data_label.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIi4SFjxPl0H"
   },
   "source": [
    "Wenn alle Daten geladen wurden, wird der Datensatz aufgeteilt in 4500 Trainingsbilder, 500 Validierungsbilder und 573 Testbilder.\n",
    "\n",
    "Die **Trainingsbilder** werden dem Klassifikationsnetzwerk während des Trainings wiederholt präsentiert und dienen dazu, dass das Modell dadurch lernt. Mithilfe der **Validierungsbilder** wird während des Trainingsvorganges validiert, wie gut das Modell mit Eingabedaten umgehen kann, die es nicht zum Lernen verwendet hat. Anhand der **Testbilder** wird nach abgeschlossenem Training evaluiert, wie gut das Modell Daten klassifizieren kann, die während des Trainings weder als Trainings- noch als Validierungsdaten gedient haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTO3fCv37P_O"
   },
   "source": [
    "*Aufteilung der Daten in Trainings-, Validierungs- und Testdatensatz:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hM8AgPPVSbUa"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: SPLIT THE DATASET\n",
    "1. Create a random permutation of integer values from 0 to 5572, associated with image indices.\n",
    "2. Split this permutation into 'idx_train', 'idx_val' and 'idx_test'. Use a \n",
    "split of 4500/500/573 and make sure no indices occur in multiple datasets.\n",
    "\n",
    "Hint:\n",
    "- Use torch.randperm(), see documentation on https://pytorch.org/docs/stable/generated/torch.randperm.html\n",
    "- Use list slicing as describes on https://railsware.com/blog/python-for-machine-learning-indexing-and-slicing-for-lists-tuples-strings-and-other-sequential-types/\n",
    "'''\n",
    "# idx_list = \n",
    "\n",
    "# idx_train = \n",
    "# idx_val = \n",
    "# idx_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLr1dWyNTQOW",
    "outputId": "ac3ef56a-0b16-482f-8c93-a00fb21f7916"
   },
   "outputs": [],
   "source": [
    "# ratio between 'Pneumonia'/'Keine Pneumonie' in training, validation and test data\n",
    "print(torch.sum(data_label[idx_train])/abs(torch.sum(data_label[idx_train]-1)))\n",
    "print(torch.sum(data_label[idx_val])/abs(torch.sum(data_label[idx_val]-1)))\n",
    "print(torch.sum(data_label[idx_test])/abs(torch.sum(data_label[idx_test]-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8p4NNLa7WeH"
   },
   "source": [
    "*Darstellung eines zufällig ausgewählten Beispielbildes aus dem Datensatz:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "atDtsZ-WTQOX",
    "outputId": "81043b3b-76a3-4d97-ee04-d4fe91e29628"
   },
   "outputs": [],
   "source": [
    "# visualize example images with expert labels\n",
    "idx = np.random.randint(0, 5572)\n",
    "plt.imshow(data_img[idx,0,:,:], cmap='gray')\n",
    "plt.colorbar()\n",
    "if int(data_label[idx]) == 1:\n",
    "    title = f\"Bild Nr. {idx}: Pneumonie\"\n",
    "else:\n",
    "    title = f\"Bild Nr. {idx}: Keine Pneumonie\"\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6_sEWAIFRHX"
   },
   "source": [
    "### 4. Netzwerkarchitektur\n",
    "Das Modell, das in dieser Lektion zur Klassifikation von Röntgenthoraxbildern verwendet werden soll, ist ein Faltungsnetzwerk bestehend aus vier Blöcken mit Faltungen, Batch-Normalisierungen und Aktivierungen, gefolgt von einem Modul aus voll-verbundenen Schichten.\n",
    "\n",
    "In diesem Unterkapitel werden die einzelnen Bausteine des Klassifikationsnetzwerkes beschrieben und ein Einblick in deren Programmierung gegeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSqZeQfCK8AD"
   },
   "source": [
    "#### Bausteine\n",
    "##### *1. Faltungsblöcke*\n",
    "Die insgesamt vier Faltungsblöcke bestehen jeweils aus zweimal der Abfolge einer zweidimensionalen Faltung, gefolgt von einer Batch-Normalisierung und einer Aktivierung. Auf jeden der Faltungsblöcke folgt ein Max-Pooling. In jedem Faltungsblock erhöht sich die Anzahl der Merkmalskanäle, während jede Pooling-Operation die räumliche Auflösung reduziert.\n",
    "\n",
    "```\n",
    "# Code für einen Faltungsblock\n",
    "conv_block = nn.Sequential(nn.Conv2d(n_ch_in, n_ch_out, kernel_size),\n",
    "                           nn.BatchNorm2d(n_ch_out),\n",
    "                           nn.ReLU(),\n",
    "\n",
    "                           nn.Conv2d(n_ch_out, n_ch_out, kernel_size),\n",
    "                           nn.BatchNorm2d(n_ch_out),\n",
    "                           nn.ReLU()\n",
    "                          )\n",
    "```\n",
    "##### *2. Modul aus voll-verbundenen Schichten*\n",
    "Das Klassifikationsmodell wird durch ein Modul bestehend aus voll-verbundenen Schichten abgeschlossen. Dabei wechseln sich lineare Transformationen mit Aktivierungsfunktionen ab. Die Ausgabe der letzten Schicht besitzt zwei Merkmalskanäle - entsprechend der Anzahl der Klassen (Pneumonie/keine Pneumonie).\n",
    "\n",
    "```\n",
    "# Code für das Modul aus voll-verbundenen Schichten\n",
    "fc_block = nn.Sequential(nn.Linear(n_in, n_out_tmp),\n",
    "                         nn.ReLU(),\n",
    "\n",
    "                         nn.Linear(n_out_tmp, n_out),\n",
    "                         nn.ReLU(),\n",
    "\n",
    "                         nn.Linear(n_out_tmp, n_classes)\n",
    "                        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzM8xt_h7lMS"
   },
   "source": [
    "*Definition des Modells \"classificationCNN\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dxWEYWyVaIR"
   },
   "outputs": [],
   "source": [
    "# classification model\n",
    "class classificationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''\n",
    "        TODO: BUILD THE CNN\n",
    "        1. Build four convolution blocks by simply copying the given code in the description above.\n",
    "        2. Set the number of feature channels by assinging integer values to 'n_ch_in' and 'n_ch_out'.\n",
    "             Since our data consists of one-dimensional greyscale images, the 'n_ch_in'\n",
    "             of the first block is 1. \n",
    "             The choice of parameters is theoretically up to you, but it is recommended\n",
    "             to bring the 'n_ch_out' up 10 in the first conv_block.\n",
    "             Then double the number of feature channel within every next conv_block\n",
    "             by assigning 'n_ch_in' the value of the previous 'n_ch_out'\n",
    "             and assigning 'n_ch_out' the double value of 'n_ch_in'.\n",
    "        3. Set the kernel sizes to 3.\n",
    "        '''\n",
    "        # self.conv_block0 = \n",
    "\n",
    "        # self.conv_block1 = \n",
    "\n",
    "        # self.conv_block2 = \n",
    "\n",
    "        # self.conv_block3 = \n",
    "\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(4*4*80, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 2)\n",
    "        )\n",
    "\n",
    "        self.maxPool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.maxPool(self.conv_block0(x))\n",
    "        x = self.maxPool(self.conv_block1(x))\n",
    "        x = self.maxPool(self.conv_block2(x))\n",
    "        x = self.maxPool(self.conv_block3(x))\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkMCc53QF8mB"
   },
   "source": [
    "### 5. Training\n",
    "Während des Trainingsprozesses werden dem im vorherigen Unterkapitel Netzwerkarchitektur beschriebenen Modell **Trainingsbilder** mit bekannten **Grundwahrheiten** übergeben. Das **Modell** trifft zu jedem Eingabebild eine **Vorhersage**, die dann über die **Lossfunktion** mit der Grundwahrheit verglichen wird. Basierend auf der Ausgabe der Lossfunktion werden durch die **Backpropagation** die **Parameter** des Modells angepasst. Dieser Prozess wird so lange wiederholt, bis die Parameter des Modells so weit angepasst sind, dass sie bei der Backpropagation nicht mehr geändert werden müssen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYAl-rlH7w21"
   },
   "source": [
    "*Definition der Lossfunktion und einzelner Trainingsparameter, wie zum Beispiel der Anzahl an Trainingsepochen oder der Batch-Größe:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssw288ilTQOY"
   },
   "outputs": [],
   "source": [
    "# set up loss function\n",
    "class_weight = torch.sqrt(1.0/(torch.bincount(data_label[idx_train].view(-1)).float()))\n",
    "class_weight = class_weight/class_weight.mean()\n",
    "class_weight = class_weight\n",
    "loss_function = nn.CrossEntropyLoss(weight=class_weight)\n",
    "\n",
    "# set parameters for batch size and number of epochs\n",
    "batch_size = 25\n",
    "batch_size_val = 25\n",
    "n_epochs = 26\n",
    "every_epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QaIlBU97_SQg"
   },
   "source": [
    "*Trainingsschleife:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThbA_5QvW5k0"
   },
   "outputs": [],
   "source": [
    "# build models\n",
    "model = classificationCNN()\n",
    "bestNet = classificationCNN()\n",
    "\n",
    "# set up optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=(9*n_epochs)//10, gamma=0.1)\n",
    "\n",
    "losses_training = []\n",
    "losses_validation = []\n",
    "\n",
    "best_loss = np.infty\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# training loop with validation phase\n",
    "for epoch in range(n_epochs): \n",
    "    \n",
    "    ########################################\n",
    "    #               TRAINING               #\n",
    "    ########################################\n",
    "    \n",
    "    sum_loss = 0\n",
    "    \n",
    "    # create batch of randomly shuffled training images\n",
    "    train_batches = torch.randperm(len(idx_train))[:len(idx_train)-len(idx_train)%batch_size].view(-1,batch_size)\n",
    "    \n",
    "    # parameters must be trainable\n",
    "    model.train()\n",
    "    with torch.set_grad_enabled(True):\n",
    "        \n",
    "        # main loop to process all training samples (packed into batches)\n",
    "        for batch_idx in train_batches:\n",
    "            '''\n",
    "            TODO: PERFORM THE FORWARD PASS AND CALCULATE LOSS\n",
    "            1. Load the input data by taking the current 'batch_idx' of 'data_img'.\n",
    "            2. Do the same for the label by taking the current 'batch_idx' of 'data_label'.\n",
    "            3. Pass the input data forward through the model by giving the previously \n",
    "                loaded input data to the 'model()' as an argument. The return value\n",
    "                is the models 'prediction'.\n",
    "            4. Calculate the loss by passing the 'prediction' as first argument and\n",
    "                'label' as second argument to the 'loss_function'.\n",
    "            Hint: Streamlit version...\n",
    "            '''\n",
    "            # input = \n",
    "\n",
    "            # label = \n",
    "\n",
    "            # prediction = \n",
    "\n",
    "            # loss = \n",
    "            \n",
    "            # backpropagation step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            sum_loss += loss.item()\n",
    "      \n",
    "        losses_training.append(sum_loss/ len(train_batches))\n",
    "\n",
    "    ########################################\n",
    "    #              VALIDATION              #\n",
    "    ########################################\n",
    "  \n",
    "    sum_loss = 0\n",
    "     \n",
    "    # parameters must not be trainable\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        \n",
    "        val_batches = torch.randperm(len(idx_val))[:len(idx_val)-len(idx_val)%batch_size_val].view(-1,batch_size_val)\n",
    "\n",
    "        # main loop to process all validation samples (packed into batches)\n",
    "        for batch_idx in val_batches:\n",
    "            '''\n",
    "            TODO: PERFORM THE FORWARD PASS\n",
    "            1. Load the input data by taking the current 'batch_idx' of 'data_img'.\n",
    "            2. Do the same for the label by taking the current 'batch_idx' of 'data_label'.\n",
    "            3. Pass the input data forward through the model by giving the previously \n",
    "                loaded input data to the 'model()' as an argument. The return value\n",
    "                is the models 'prediction'.\n",
    "            4. Calculate the loss by passing the 'prediction' as first argument and\n",
    "                'label' as second argument to the 'loss_function'.\n",
    "            '''\n",
    "            # input = \n",
    "\n",
    "            # label = \n",
    "\n",
    "            # prediction = \n",
    "\n",
    "            # loss = \n",
    "            \n",
    "            # no need to backpropagate here\n",
    "            sum_loss += loss.item() / len(val_batches)\n",
    "      \n",
    "        validation_loss = sum_loss\n",
    "        losses_validation.append(validation_loss)\n",
    "        \n",
    "        if validation_loss < best_loss:\n",
    "            best_loss = validation_loss\n",
    "            best_state_dict = bestNet.state_dict()\n",
    "            state_dict = model.state_dict()           \n",
    "            for name, param in state_dict.items():\n",
    "                best_state_dict[name].copy_(param)\n",
    "      \n",
    "    # scheduler will adapt the learning rate once the step count reaches threshold\n",
    "    scheduler.step()  \n",
    "    \n",
    "    if epoch % every_epoch == 0:\n",
    "        t1 = time.time()\n",
    "        print(\"{:.2f}\".format(t1-t0), 's --- Epoch ' + str(epoch) +': Training loss ' + str(losses_training[-1]) + ', Validation loss ' + str(losses_validation[-1]))\n",
    "        \n",
    "print('Finished Training')\n",
    "print('Best validation loss: ' + str(best_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8AgMsH4_dyi"
   },
   "source": [
    "*Darstellung der Loss-Kurve:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "RE3uWhMZTQOZ",
    "outputId": "71683220-ec30-44d0-eca0-39e97eff925d"
   },
   "outputs": [],
   "source": [
    "# visualize training and validation loss over number of epochs\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(losses_training))[1:], losses_training[1:])\n",
    "plt.plot(np.arange(len(losses_training))[1:], losses_validation[1:])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(('Train Loss', 'Val. Loss'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pq55MryGpMx"
   },
   "source": [
    "### 6. Evaluation\n",
    "Im vorherigen Unterkapitel *Training* wurde das Modell `bestNet` abgespeichert, das auf den Validierungsdaten die besten Ergebnisse erzielt hat. Dieses Modell soll jetzt während der sogenannten **Inferenz** auf die Testdaten angewendet werden, um zu evaluieren, wie gut das Modell auf Bildern klassifizieren kann, die ihm während der Trainingsphase noch nicht präsentiert wurden.\n",
    "\n",
    "Während der Evaluation wird bestimmt, bei wie vielen Fällen in den Testdaten\n",
    "\n",
    "- korrekterweise eine Pneumonie erkannt wurde (True Positive, **TP** )\n",
    "- korrekterweise keine Pneumonie erkannt wurde (True Negative, **TN**)\n",
    "- fälschlicherweise eine Pneumonie erkannt wurde (False Positive, **FP**)\n",
    "- fälschlicherweise keine Pneumonie erkannt wurde (False Negative, **FN**).\n",
    "\n",
    "Die **Accuracy** gibt an, welcher Anteil an Bildern insgesamt richtig klassifiziert wurden:\n",
    "\n",
    "`ACCURACY= (TP+TN) / (TP+TN+FP+FN)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLcaCZT0_hwn"
   },
   "source": [
    "*Testschleife:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UxHwP75TQOa",
    "outputId": "8a165135-e6e3-4383-fecb-842deaec09de"
   },
   "outputs": [],
   "source": [
    "# evaluation inference\n",
    "bestNet.eval()\n",
    "\n",
    "y_gt = []\n",
    "y_pred = []\n",
    "\n",
    "# testing loop\n",
    "for ind in idx_test:\n",
    "\n",
    "    ########################################\n",
    "    #                 TEST                 #\n",
    "    ########################################\n",
    "\n",
    "    classifications = []\n",
    "\n",
    "    # load test images and ground truth label\n",
    "    source_image = data_img[ind].unsqueeze(0)\n",
    "    target_label = data_label[ind]\n",
    "\n",
    "    # apply model\n",
    "    classification = bestNet(source_image).argmax(1)\n",
    "\n",
    "    y_gt.append(target_label.item())\n",
    "    y_pred.append(classification.item())\n",
    "        \n",
    "# calculate TP, TN, FP, FN and accuracy\n",
    "tn, fp, fn, tp = confusion_matrix(y_gt, y_pred).ravel()\n",
    "print('Scores on test dataset:')\n",
    "print('TP: ', tp, 'TN: ', tn, 'FP: ', fp, 'FN: ', fn)\n",
    "\n",
    "acc = (tp+tn)/len(idx_test)\n",
    "print('ACCURACY = ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fhs84LKhIfUI"
   },
   "source": [
    "### 7. Ergebnisvisualisierung\n",
    "Hier wird visualisiert, welche Röntgenbilder richtig und welche Röntgenbilder aus dem Testdatensatz falsch klassifiziert wurden.\n",
    "\n",
    "In der Bildüberschrift wird jeweils angegeben, ob es sich bei dem angezeigten Fall um TP (True Positive), TN (True Negative), FP (False Positive) oder FN (False Negative) handelt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okk5pEwX_oKO"
   },
   "source": [
    "*Visualisierung von drei falsch positiv und drei richtig positiv Ergebnissen.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3vr2rXDvTQOa",
    "outputId": "b8a086af-422f-42b8-9490-62d866de550d"
   },
   "outputs": [],
   "source": [
    "# visualize correctly and misclassified results\n",
    "n_imgs = 3\n",
    "\n",
    "# misclassified images\n",
    "idx_wrong = torch.cat(torch.where(~torch.eq(torch.tensor(y_gt), torch.tensor(y_pred))))\n",
    "ii = torch.randperm(len(idx_wrong)).view(-1)\n",
    "real_idx_wrong = idx_test[idx_wrong[ii[:n_imgs]]]\n",
    "\n",
    "print(f'{min(n_imgs, len(idx_wrong))} der {len(idx_wrong)} falsch klassifizierten Bilder:')\n",
    "\n",
    "for i in real_idx_wrong:\n",
    "    plt.imshow(data_img[i,0,:,:], cmap='gray')\n",
    "    plt.colorbar()\n",
    "    if int(data_label[i]) == 1:\n",
    "        plt.title(f'Bild Nr. {i}: FN')\n",
    "    else:\n",
    "        plt.title(f'Bild Nr. {i}: FP')\n",
    "    plt.show()\n",
    "\n",
    "# correctly classified images\n",
    "idx_correct = torch.cat(torch.where(torch.eq(torch.tensor(y_gt), torch.tensor(y_pred))))\n",
    "ii = torch.randperm(len(idx_correct)).view(-1)\n",
    "real_idx_correct = idx_test[idx_correct[ii[:n_imgs]]]\n",
    "\n",
    "print(f'{min(n_imgs, len(idx_correct))} der {len(idx_correct)} korrekt klassifizierten Bilder:')\n",
    "\n",
    "for j in real_idx_correct:\n",
    "    plt.imshow(data_img[j,0,:,:], cmap='gray')\n",
    "    plt.colorbar()\n",
    "    if int(data_label[j]) == 1:\n",
    "        plt.title(f'Bild Nr. {j}: TP')\n",
    "    else:\n",
    "        plt.title(f'Bild Nr. {j}: TN')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "learn2trust_l4_withTasks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python-learn2trust"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
